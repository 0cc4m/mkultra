{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3.8.10 64-bit"},"metadata":{"interpreter":{"hash":"3a36cc62f71b170ca22994dbd401744aeca204aa470bb3afe779afe0ab68d530"}},"colab":{"name":"tuning_finetune_lite_3.ipynb","provenance":[{"file_id":"1vDgdmnWdxn8jGzeJH6J-rzXpIGqL9DmB","timestamp":1624626774377}],"collapsed_sections":[]},"accelerator":"GPU","interpreter":{"hash":"3a36cc62f71b170ca22994dbd401744aeca204aa470bb3afe779afe0ab68d530"},"widgets":{"application/vnd.jupyter.widget-state+json":{"559b9cc17aff48cf8e916ab9ce95a0e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6209a52245144e18b98d68e4d32f8cb6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_01be81244ddc420fb8301c674feeed8a","IPY_MODEL_c22e07acc92c4186b4e354762f6e655e"]}},"6209a52245144e18b98d68e4d32f8cb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01be81244ddc420fb8301c674feeed8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d63e886233fa4fe0bf1ff24aa2b3667a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1042301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1042301,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_003736b2cda6403d9f4456ad210d9e58"}},"c22e07acc92c4186b4e354762f6e655e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bdad465306aa466fa72a6316e0fc8243","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.04M/1.04M [02:17&lt;00:00, 7.61kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3cb93ef1e7584b459b8510e3b4200cf8"}},"d63e886233fa4fe0bf1ff24aa2b3667a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"003736b2cda6403d9f4456ad210d9e58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdad465306aa466fa72a6316e0fc8243":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3cb93ef1e7584b459b8510e3b4200cf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"357b7670113b442a9fd1a67119ee912e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e033024e38134293b76bcb3d53a6205f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_61551ebeb6d44fcab3dbc2280f5af866","IPY_MODEL_9a312aaed8ad4854b903cb5449ec176f"]}},"e033024e38134293b76bcb3d53a6205f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61551ebeb6d44fcab3dbc2280f5af866":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f7e354567f90487ea0fa77d165f1f76c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb80fdde0bda47fbae1537069706b755"}},"9a312aaed8ad4854b903cb5449ec176f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8bfe1f43293141d3a0ecbf4e1af51d40","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [02:16&lt;00:00, 3.35kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_965aabe4e4594bb6af2d047d0ed22fa3"}},"f7e354567f90487ea0fa77d165f1f76c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fb80fdde0bda47fbae1537069706b755":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8bfe1f43293141d3a0ecbf4e1af51d40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"965aabe4e4594bb6af2d047d0ed22fa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c16d2c1d1614d75b2c9c63037a84c06":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_29fd758179474bb7baedfcae820b51dc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6baa65ebdaa44fa089853a02a2bde069","IPY_MODEL_8a38bbe171584f88908196c9fdd97924"]}},"29fd758179474bb7baedfcae820b51dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6baa65ebdaa44fa089853a02a2bde069":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_34065cec38b3438ca2151f8b5f5be822","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355256,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355256,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb85d0f5e4164434b2969c89a7f5b06a"}},"8a38bbe171584f88908196c9fdd97924":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5a15ea4629dc404bb9df09fca49def55","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:04&lt;00:00, 317kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d2079d5b20749df91b1d6a71f9c8313"}},"34065cec38b3438ca2151f8b5f5be822":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fb85d0f5e4164434b2969c89a7f5b06a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a15ea4629dc404bb9df09fca49def55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3d2079d5b20749df91b1d6a71f9c8313":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1960764cee28481aa32eaa32f817bab0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_36b8c807871e4032a0dc4954ed7db019","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_28cd5ff6f25848cea64d122ec7418084","IPY_MODEL_f2d412988f8b44618ee1632439c499ce"]}},"36b8c807871e4032a0dc4954ed7db019":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28cd5ff6f25848cea64d122ec7418084":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8d4baf4ba712416da5f71963918fa65e","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":100,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e1aefdd279c48758d34b97a02b52eff"}},"f2d412988f8b44618ee1632439c499ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bc5b3a994df9406d8bcc1a686853f3d2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 100/100 [1:37:26&lt;00:00, 71.80s/it, Model Step=133, Eval Loss=3.42, Acc Steps=64]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a16b6f47cc9b4cbeb1aaef0efc02eefb"}},"8d4baf4ba712416da5f71963918fa65e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5e1aefdd279c48758d34b97a02b52eff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc5b3a994df9406d8bcc1a686853f3d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a16b6f47cc9b4cbeb1aaef0efc02eefb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ja7zPK-Gvi7Z"},"source":["# Prompt Tuning\n","\n"]},{"cell_type":"code","metadata":{"id":"cE2jNS5UMXKh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624957280112,"user_tz":-480,"elapsed":64663,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}},"outputId":"63ad11fa-c02d-442b-fc9b-7e9ec6df160a"},"source":["#@title Colab-specific setup\n","\n","import torch\n","colab = 'google.colab' in str(get_ipython())\n","\n","if colab:\n","    !nvidia-smi\n","    gpu_type = torch.cuda.get_device_name(0)\n","    if gpu_type != 'Tesla T4':\n","        raise ValueError(\"Highly advised to use a T4.\")\n","\n","# Setup for Colab only\n","if colab:\n","    !pip install git+https://github.com/finetuneanon/transformers@gpt-neo-localattention3\n","    !pip install git+https://github.com/corolla-johnson/mkultra.git#egg=mkultra --log PIP_LOG\n","    !pip install gdown\n","    !pip install datasets\n","    !pip install tqdm\n","\n","# If on Colab, mount your Google Drive first!\n","if colab:\n","    from google.colab import drive\n","    drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":167,"referenced_widgets":["559b9cc17aff48cf8e916ab9ce95a0e2","6209a52245144e18b98d68e4d32f8cb6","01be81244ddc420fb8301c674feeed8a","c22e07acc92c4186b4e354762f6e655e","d63e886233fa4fe0bf1ff24aa2b3667a","003736b2cda6403d9f4456ad210d9e58","bdad465306aa466fa72a6316e0fc8243","3cb93ef1e7584b459b8510e3b4200cf8","357b7670113b442a9fd1a67119ee912e","e033024e38134293b76bcb3d53a6205f","61551ebeb6d44fcab3dbc2280f5af866","9a312aaed8ad4854b903cb5449ec176f","f7e354567f90487ea0fa77d165f1f76c","fb80fdde0bda47fbae1537069706b755","8bfe1f43293141d3a0ecbf4e1af51d40","965aabe4e4594bb6af2d047d0ed22fa3","8c16d2c1d1614d75b2c9c63037a84c06","29fd758179474bb7baedfcae820b51dc","6baa65ebdaa44fa089853a02a2bde069","8a38bbe171584f88908196c9fdd97924","34065cec38b3438ca2151f8b5f5be822","fb85d0f5e4164434b2969c89a7f5b06a","5a15ea4629dc404bb9df09fca49def55","3d2079d5b20749df91b1d6a71f9c8313"]},"id":"YjCfqiHmy1fA","executionInfo":{"status":"ok","timestamp":1624957283748,"user_tz":-480,"elapsed":3640,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}},"outputId":"bafd0146-345b-4e13-c1e0-b68ebceccbb9"},"source":["from transformers import GPT2TokenizerFast\n","tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tWYdCgONMXKm","executionInfo":{"status":"ok","timestamp":1624960163471,"user_tz":-480,"elapsed":335,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}}},"source":["#-----------------------#\n","#  Training Parameters  #\n","#-----------------------#\n","\n","# This decides the length of your soft prompt in tokens.\n","# They will be initialized from the first n tokens of your dataset.\n","n_tokens = 100\n","\n","# Set this to a string to start with a specific tokenized string.\n","# Be aware of the number of tokens.\n","initial_prompt = None\n","\n","if initial_prompt is not None:\n","    print(f\"Initial prompt length: {len(tokenizer.encode(initial_prompt))} tokens\")\n","\n","# Decide the length of your training blocks in tokens.\n","# Safe sizes for gpt-neo-2.7B-halved:\n","#  - 700 on a Colab T4 (16GB)\n","#  - 400 on a Colab K80 (12GB)\n","#  - 32 on a GTX1080 (8GB)\n","# If it seems a bit small, don't worry!\n","# Soft prompts can be moved forward in context for the best effect.\n","block_size = 700\n","\n","# Name your soft prompt project.\n","sp_name = 'nm-experimental-cyclic-grad'\n","\n","# What's the name of model you'll be using?\n","model_name = 'gpt-neo-2.7B'\n","\n","# Specify the model directory or huggingface name.\n","model_dir = \"/content/drive/MyDrive/models/gpt-neo-2.7B-halved/\"\n","\n","# It is recommended to use finetuneanon's FP16 fork of gpt-neo-2.7B, which can be obtained from this magnet link:\n","# magnet:?xt=urn:btih:f50bb4e259d2f96aa9151443950b0d2b899a097c&dn=gpt-neo-2.7B-halved&tr=http%3A%2F%2Fopenbittorrent.com%3A80%2Fannounce&tr=http%3A%2F%2Ft.nyaatracker.com%3A80%2Fannounce&tr=udp%3A%2F%2Fopen.stealth.si%3A80%2Fannounce\n","# Once you've downloaded it to your local machine, create a 'models' folder in your Google Drive and upload it there.\n","\n","# Specify the path to the text file used for training.\n","text_path = \"/content/drive/MyDrive/datasets/nm_burning_chrome.txt\"\n","\n","# Specify the project directory.\n","project_dir = f\"/content/drive/MyDrive/soft_prompts/{sp_name}-{model_name}/\"\n","\n","# Checkpoint interval in steps.\n","checkpoint_interval = 1\n","\n","# Evaluation interval in steps.\n","eval_interval = 1\n","\n","# How many blocks to use for evaluation.\n","eval_blocks = 20\n","\n","# Adafactor hyperparameters\n","optimizer_params = {\n","    # Fixed learning rate, recommend 1e-4 to 1e-3\n","    \"lr\": 5e-4,\n","    \n","    # 1st momentum, recommend 0\n","    \"beta1\": 0.0,\n","\n","    # 2nd momentum decay schedule, recommend -0.3 (lower is slower)\n","    \"decay_rate\": -0.3,\n","\n","    # Weight decay, recommend 1e-5\n","    \"weight_decay\": 1e-5,\n","    \n","    # Update scaling, recommend False\n","    \"scale_parameter\": False,\n","    \n","    # Built-in LR scheduler, recommend False\n","    \"relative_step\": False\n","    }\n","\n","# Cyclic gradient accumulation pattern.\n","# Doubling accumulation is equivalent to halving learning rate.\n","acc_pattern = [32, 32, 32, 32, 64, 64]\n","\n","# Stop training after this many evals without improvement.\n","# If '0', don't stop early.\n","plateau_steps = 6"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEVELdEDttvO","executionInfo":{"status":"ok","timestamp":1624957582326,"user_tz":-480,"elapsed":164757,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}}},"source":["#@title Load model\n","\n","from mkultra.tuning import GPTNeoPromptTuningLM\n","\n","if 'model' not in globals():\n","    model = GPTNeoPromptTuningLM.from_pretrained(model_dir).half().to(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BZAT90ZCMXKo","cellView":"form","executionInfo":{"status":"ok","timestamp":1624957588717,"user_tz":-480,"elapsed":1002,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}},"outputId":"88153490-b048-4bb0-dfb7-2618bd59d76f"},"source":["#@title Initialize project\n","#@markdown This will load the latest checkpoint if the project directory already exists.\n","\n","from mkultra.soft_prompt import SoftPrompt\n","from transformers import Adafactor\n","import os\n","\n","filename_for_checkpoint = lambda step: f\"{sp_name}-{model_name}-step-{step}.json\"\n","loaded_sp = None\n","project_files = None\n","\n","# Look for existing project directory\n","try:\n","    os.makedirs(project_dir)\n","    print(f\"Created project directory at {project_dir}\")\n","except FileExistsError:\n","    print(f\"Found project directory at {project_dir}\")\n","\n","# Look for existing checkpoints\n","project_files = os.listdir(project_dir)\n","if project_files is not None:\n","    checkpoint_files = [check_file for check_file in project_files if ('-step-' in check_file) ]\n","\n","    if len(checkpoint_files) > 0:\n","        highest_step = max([ int(check_file[check_file.rfind('-step-')+6:-5]) for check_file in checkpoint_files ])\n","        loaded_sp = SoftPrompt.from_file( os.path.join(project_dir, filename_for_checkpoint(highest_step)) )\n","        print(f\"Loading latest checkpoint: {highest_step}\")\n","    else:\n","        print(\"No checkpoints found\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"pf7wZnxNtR29","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1624957594029,"user_tz":-480,"elapsed":1302,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}},"outputId":"627286f4-376c-4a5f-c1cc-c2c0c7b9f03f"},"source":["#@title Process dataset\n","#@markdown This will load an existing set\n","#@markdown of tokens if present in the project directory.\n","\n","import json\n","import math\n","\n","text_tokenized = None\n","tokens_path = os.path.join(project_dir,\"tokens.json\")\n","\n","# See if we already have a tokens file\n","try:\n","    with open(tokens_path, 'r', encoding='utf-8') as file:\n","        text_tokenized = json.load(file)\n","        print(\"Loaded existing tokens.json file\")\n","\n","except FileNotFoundError:\n","    print(\"No tokens.json exists, creating it...\")\n","\n","# If not, make one now\n","if text_tokenized is None:\n","\n","    with open(text_path, 'r', encoding='utf-8') as file:\n","        text = file.read()\n","    text_tokenized = tokenizer.encode(text)\n","    \n","    with open(tokens_path, 'x', encoding='utf-8') as file:\n","        json.dump(text_tokenized, file)\n","\n","text_length = len(text_tokenized)\n","num_blocks = math.ceil(text_length/block_size)\n","\n","print(f\"Length of text: {len(text_tokenized)} tokens\")\n","print(f\"Number of blocks: {num_blocks}, each {block_size} tokens\")\n","\n","# Partition tokens into blocks\n","blocks = list()\n","for block_num in range(num_blocks):\n","    start = block_num * block_size\n","    end = min(start + block_size, text_length)\n","    blocks.append( text_tokenized[start:end] )\n","\n","block_order_path = os.path.join(project_dir, \"block_order.json\")\n","\n","# See if we already have a block_order file\n","try:\n","    with open(block_order_path, 'r', encoding='utf-8') as file:\n","        block_order = json.load(file)\n","        print(\"Loaded existing block_order.json file\")\n","\n","except FileNotFoundError:\n","    print(\"No block_order.json exists, creating it...\")\n","    block_order = [*range(num_blocks)]\n","\n","    with open(block_order_path, 'x', encoding='utf-8') as file:\n","        json.dump(block_order, file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TI_f3H5lXeLt","executionInfo":{"status":"ok","timestamp":1624957596620,"user_tz":-480,"elapsed":2,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}}},"source":["#@title Initialize soft prompt in model\n","#@markdown If a checkpoint is present, use that.\n","if loaded_sp is None:\n","    if initial_prompt is None:\n","        model.initialize_soft_prompt(n_tokens=n_tokens)\n","    else:\n","        initial_sp = SoftPrompt.from_string(initial_prompt, model, tokenizer)\n","        print(f\"Initial prompt length: {len(initial_sp)}\")\n","        model.set_soft_prompt(initial_sp)\n","\n","    sp_step = 0\n","    eval_loss = 100\n","else:\n","    model.set_soft_prompt(loaded_sp)\n","    sp_step = loaded_sp._metadata['step']\n","    eval_loss = loaded_sp._metadata['loss']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zKFXv5Zo366O","executionInfo":{"status":"ok","timestamp":1624957601768,"user_tz":-480,"elapsed":3,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}}},"source":["# Feed soft params to optimizer\n","optimizer_params['params'] = [model.get_soft_params()]\n","optimizer = Adafactor(**optimizer_params)\n","optimizer.state['step'] = sp_step"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYaLKE1YtR3C","executionInfo":{"status":"ok","timestamp":1624957604094,"user_tz":-480,"elapsed":3,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}}},"source":["import math\n","\n","# Configure number of steps to train for.\n","# One step is (acc_steps) forward passes.\n","num_training_steps = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D0Zurqzx6OIu","executionInfo":{"status":"ok","timestamp":1624957624779,"user_tz":-480,"elapsed":372,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}}},"source":["# Function for gradient accumulation scheduling\n","def get_acc_steps(sp_step):\n","    notch = sp_step%len(acc_pattern)\n","    return acc_pattern[notch]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["outputPrepend"],"id":"ImdPj_CftR3C","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["1960764cee28481aa32eaa32f817bab0","36b8c807871e4032a0dc4954ed7db019","28cd5ff6f25848cea64d122ec7418084","f2d412988f8b44618ee1632439c499ce","8d4baf4ba712416da5f71963918fa65e","5e1aefdd279c48758d34b97a02b52eff","bc5b3a994df9406d8bcc1a686853f3d2","a16b6f47cc9b4cbeb1aaef0efc02eefb"]},"executionInfo":{"status":"ok","timestamp":1624966012546,"user_tz":-480,"elapsed":902311,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}},"outputId":"de8c1509-585e-41a7-e902-fdaf1824e700"},"source":["#@title Train the soft prompt\n","\n","from tqdm.notebook import tqdm\n","import random\n","import torch\n","import math\n","\n","torch.cuda.empty_cache()\n","loss_log_path = os.path.join(project_dir,\"loss_log.csv\")\n","bar = tqdm(total=num_training_steps)\n","optimizer.state['step'] = sp_step\n","evals_since_last_improvement = 0\n","best_eval = float('inf')\n","\n","# Fix eval order\n","eval_order = [*range(num_blocks)]\n","random.seed(1234)\n","random.shuffle(eval_order)\n","\n","for session_step in range(num_training_steps):\n","      model.train()\n","\n","      acc_steps = get_acc_steps(sp_step)\n","\n","      for i in range(acc_steps):\n","          idx = (sp_step*acc_steps + i) % num_blocks\n","\n","          # Shuffle blocks every epoch\n","          if idx == 0:\n","              random.shuffle(block_order)\n","              with open(block_order_path, 'w', encoding='utf-8') as file:\n","                  json.dump(block_order, file)\n","\n","          block = blocks[block_order[idx]]\n","\n","          input_ids = torch.LongTensor(block).unsqueeze(0).cuda().detach()\n","          \n","          # Forward pass and optimize\n","          outputs = model(input_ids=input_ids, labels=input_ids)\n","          loss = outputs.loss\n","          loss.backward()\n","\n","          instant_loss = loss.item()\n","          if math.isnan(instant_loss):\n","              torch.cuda.empty_cache()\n","              raise KeyboardInterrupt\n","\n","          # Discard tensor that was moved to GPU\n","          del input_ids\n","          torch.cuda.empty_cache()\n","\n","      # Accumulate gradients\n","      optimizer.step()\n","      optimizer.zero_grad()\n","\n","      if math.isnan(instant_loss):\n","          torch.cuda.empty_cache()\n","          raise KeyboardInterrupt\n","\n","      # Evaluate model and plot loss\n","      if sp_step%eval_interval == 0:\n","          model.eval()\n","          torch.cuda.empty_cache()\n","          eval_loss = 0\n","\n","          with torch.no_grad():\n","              for eval_step in range(eval_blocks):\n","                  block = blocks[eval_order[eval_step]]\n","                  input_ids = torch.LongTensor(block).unsqueeze(0).cuda().detach()\n","                  eval_loss += model(input_ids=input_ids, labels=input_ids).loss.item()\n","                  \n","                  # Discard tensor that was moved to GPU\n","                  del input_ids\n","                  torch.cuda.empty_cache()\n","\n","          eval_loss /= eval_blocks\n","\n","          with open(loss_log_path, 'a', encoding='utf-8') as file:\n","              file.write(f\"{sp_step},{eval_loss}\\n\")\n","          \n","          # Stop if loss has plateaued\n","          if eval_loss < best_eval:\n","              best_eval = eval_loss\n","              evals_since_last_improvement = 0\n","          else:\n","              evals_since_last_improvement += 1\n","          if evals_since_last_improvement > plateau_steps:\n","              print(f\"No improvement for {plateau_steps} evals\")\n","              break\n","\n","      # Save checkpoint every so often\n","      if sp_step%checkpoint_interval == 0:\n","          sp = SoftPrompt.from_tuning_model(model,\n","              {\"name\" : sp_name + f\"-step-{sp_step}\",\n","               \"step\"  : sp_step,\n","               \"loss\"  : eval_loss})\n","          sp.to_file( os.path.join( project_dir,filename_for_checkpoint(sp_step) ) )\n","\n","      bar.set_postfix({\n","          \"Model Step\" : sp_step,\n","          \"Eval Loss\"  : eval_loss,\n","          \"Acc Steps\"  : acc_steps\n","      })\n","      bar.update(1)\n","      sp_step += 1\n","\n","# Save a checkpoint once done\n","sp = SoftPrompt.from_tuning_model(model,\n","    {\"name\"  : sp_name + f\"-step-{sp_step}\",\n","     \"step\"  : sp_step,\n","     \"loss\"  : eval_loss})\n","sp.to_file( os.path.join( project_dir,filename_for_checkpoint(sp_step) ) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-UdO6kRiaptn","cellView":"form","executionInfo":{"status":"ok","timestamp":1624959624508,"user_tz":-480,"elapsed":317,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}}},"source":["#@title Flush memory after interrupting training\n","#@markdown This will *hopefully* prevent a CUDA out-of-memory error.\n","try:\n","  del input_ids\n","except Exception:\n","  pass\n","torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YKypaYDOtR3E","colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"status":"error","timestamp":1624887298896,"user_tz":-480,"elapsed":5791,"user":{"displayName":"Corolla Johnson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_pEuQ9U8Dr-UNfC7oW11xsEjfpJyt8z-6DatvA=s64","userId":"07978228634594951074"}},"outputId":"ed3f45af-5b73-4089-f5b5-b7e843817179"},"source":["# Try generating with your model\n","model.eval()\n","\n","test = \"Shino slipped out of her drenched pilot suit and cracked open a cold one,\"\n","\n","call = tokenizer(test, return_tensors=\"pt\").input_ids.cuda()\n","\n","basic_output = model.generate(\n","    input_ids=call,\n","    do_sample=True,\n","    min_length=call.shape[-1] + 100,\n","    max_length=call.shape[-1] + 100,\n","    temperature=1.2,\n","    tfs = 0.9,\n","    repetition_penalty = 3.0,\n","    pad_token_id=tokenizer.eos_token_id\n",")\n","print(tokenizer.decode(basic_output[0]))"],"execution_count":null,"outputs":[]}]}